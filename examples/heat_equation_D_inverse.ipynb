{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample script to learn a PDE parameter in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from torchphysics.problem import Variable, Parameter\n",
    "from torchphysics.setting import Setting\n",
    "from torchphysics.problem.domain import (Rectangle,\n",
    "                                           Interval)\n",
    "from torchphysics.problem.condition import (DirichletCondition,\n",
    "                                              DiffEqCondition,\n",
    "                                              DataCondition)\n",
    "from torchphysics.models.fcn import SimpleFCN\n",
    "from torchphysics import PINNModule\n",
    "from torchphysics.utils import laplacian, grad\n",
    "from torchphysics.utils.fdm import FDM, create_validation_data\n",
    "from torchphysics.utils.plot import Plotter\n",
    "from torchphysics.utils.evaluation import (get_min_max_inside,\n",
    "                                             get_min_max_boundary)\n",
    "from torchphysics.setting import Setting\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" # select GPUs to use\n",
    "\n",
    "#pl.seed_everything(43) # set a global seed\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some parameters that describe the setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 10, 10\n",
    "t0, tend = 0, 3\n",
    "temp_hot = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the independent variables of the PDE, which will later determine the inputs to the NN. Every variable has a domain and can have one or more boundary conditions.\n",
    "\n",
    "Now we also define a Parameter which will be optimized during training, based on given training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(name='x',\n",
    "             order=2,\n",
    "             domain=Rectangle(corner_dl=[0, 0],\n",
    "                              corner_dr=[w, 0],\n",
    "                              corner_tl=[0, h]),\n",
    "             train_conditions={},\n",
    "             val_conditions={})\n",
    "t = Variable(name='t',\n",
    "             order=1,\n",
    "             domain=Interval(low_bound=0,\n",
    "                             up_bound=tend),\n",
    "             train_conditions={},\n",
    "             val_conditions={})\n",
    "\n",
    "m = torch.Tensor((5.0,))\n",
    "D = Parameter(init=m, name='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same notation, as in the forward problem, we can define a PDE-condition to the inner of the domain.\n",
    "\n",
    "Here we also include the parameter 'D' in the (dummy) equation, that should be computed. Therefore the pde-condition gets now an additional input: params. This input contains all learnable paramters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = torch.nn.MSELoss()\n",
    "\n",
    "def pde(u, **input):\n",
    "    return grad(u, input['t']) - input['D']*laplacian(u, input['x'])\n",
    "\n",
    "train_cond = DiffEqCondition(pde=pde,\n",
    "                             name='pde',\n",
    "                             norm=norm,\n",
    "                             sampling_strategy='random',\n",
    "                             weight=1.0,\n",
    "                             dataset_size=500,\n",
    "                             data_plot_variables=('x','t'))\n",
    "\n",
    "def x_dirichlet_fun(x):\n",
    "    return 0\n",
    "\n",
    "x.add_train_condition(DirichletCondition(dirichlet_fun=x_dirichlet_fun,\n",
    "                                         whole_batch=False,\n",
    "                                         name='dirichlet',\n",
    "                                         sampling_strategy='random',\n",
    "                                         boundary_sampling_strategy='random',\n",
    "                                         norm=norm,\n",
    "                                         weight=1.0,\n",
    "                                         dataset_size=500,\n",
    "                                         data_plot_variables=('x','t')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of adding addtional conditions for the inital and boundary values we now create a DataCondition, by using a FDM to solve the forward problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for FDM-Solution: 0.024542500003008172\n"
     ]
    }
   ],
   "source": [
    "D_list = [2] # This D is the value we will later try to find!\n",
    "domain_dic = {'x': [[0,w], [0,h]]}\n",
    "dx, dy = 0.5, 0.5\n",
    "step_width_dict = {'x': [dx, dy]}\n",
    "time_interval = [t0, tend]\n",
    "def inital_condition(**input):\n",
    "    return temp_hot * np.sin(np.pi/w*input['x'][0]) * np.sin(np.pi/h*input['x'][1]) \n",
    "fdm_start = timer()\n",
    "domain, time, u = FDM(domain_dic, step_width_dict, time_interval, \n",
    "                      D_list, inital_condition)\n",
    "fdm_end = timer()\n",
    "print('Time for FDM-Solution:', fdm_end-fdm_start)\n",
    "\n",
    "data_x, data_u = create_validation_data(domain, time, u, D_list, D_is_input = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont want to use all points of the FDM-solution, therefore for now pick only 5000 random values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(data_u), 5, replace=False)\n",
    "data_u = data_u[index]\n",
    "for name in data_x:\n",
    "    data_x[name] = data_x[name][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these points we now create a DataCondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cond = DataCondition(data_inp=data_x,\n",
    "                         data_out=data_u,\n",
    "                         name='data_cond',\n",
    "                         norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always the variables as well as the conditions for the inner part of the domain are collected in a Setting. Now we also add the parameters that should be trained in a dictonary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = Setting(variables=(x, t),\n",
    "                train_conditions={'pde': train_cond, 'data': data_cond},\n",
    "                val_conditions={},\n",
    "                n_iterations=500,\n",
    "                parameters={'D': D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem we use (like always) the PINNModule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a3be27e379de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m solver = PINNModule(model=SimpleFCN(input_dim=3, depth=3, width=20),\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Start with adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     )\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'input_dim'"
     ]
    }
   ],
   "source": [
    "solver = PINNModule(model=SimpleFCN(input_dim=3, depth=3, width=20),\n",
    "                    optimizer=torch.optim.Adam, # Start with adam\n",
    "                    lr=1e-2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a lightning trainer and train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus='-1' if torch.cuda.is_available() else None,\n",
    "                     logger=False,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     benchmark=True,\n",
    "                     check_val_every_n_epoch=100,\n",
    "                     log_every_n_steps=1,\n",
    "                     max_epochs=4,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "trainer.fit(solver, setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.parameters['D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to lbfgs\n",
    "solver.lr = 0.05\n",
    "solver.optim_params = {'max_iter': 1, 'history_size': 100}\n",
    "solver.optimizer = torch.optim.LBFGS\n",
    "trainer = pl.Trainer(gpus='-1' if torch.cuda.is_available() else None,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     benchmark=True,\n",
    "                     logger=False,\n",
    "                     check_val_every_n_epoch=100,\n",
    "                     log_every_n_steps=100,\n",
    "                     max_epochs=3,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "trainer.fit(solver, setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again check the value of D. It is pretty close to D = 2, what we used in the FDM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup.parameters['D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only did we find D, the neural network also learned the solution of our problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchphysics.utils.plot import _plot\n",
    "fig = _plot(solver.model, plot_variables=x, points=100, dic_for_other_variables={'t': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5471d372aecbf763f050aece93ed861d8318175083d9494b12a3b32f7831ffe8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

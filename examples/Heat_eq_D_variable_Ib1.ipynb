{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve a heat equation for variable diffusion D\n",
    "This script includes D as an input to the network, such that the trained network solves the heat equation for a whole range of diffusion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from torchphysics.problem import Variable\n",
    "from torchphysics.setting import Setting\n",
    "from torchphysics.problem.domain import (Rectangle,\n",
    "                                           Interval)\n",
    "from torchphysics.problem.condition import (DirichletCondition,\n",
    "                                              DiffEqCondition,\n",
    "                                              DataCondition)\n",
    "from torchphysics.models.fcn import SimpleFCN\n",
    "from torchphysics import PINNModule\n",
    "from torchphysics.utils import laplacian, grad\n",
    "from torchphysics.utils.fdm import FDM, create_validation_data\n",
    "from torchphysics.utils.plot import Plotter\n",
    "from torchphysics.utils.evaluation import (get_min_max_inside,\n",
    "                                             get_min_max_boundary)\n",
    "from torchphysics.setting import Setting\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # select GPUs to use\n",
    "\n",
    "#pl.seed_everything(43) # set a global seed\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some parameters that describe the setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 40, 40\n",
    "t0, tend = 0, 3\n",
    "temp_hot = 10\n",
    "D_low, D_up = 5, 25  # set here the interval boundary for D\n",
    "\n",
    "u = 'u'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the independent variables of the PDE, which will later determine the inputs to the NN. Every variable has a domain and can have one or more boundary conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(name='x',\n",
    "             order=2,\n",
    "             domain=Rectangle(corner_dl=[0, 0],\n",
    "                              corner_dr=[w, 0],\n",
    "                              corner_tl=[0, h]),\n",
    "             train_conditions={},\n",
    "             val_conditions={})\n",
    "t = Variable(name='t',\n",
    "             order=1,\n",
    "             domain=Interval(low_bound=0,\n",
    "                             up_bound=tend),\n",
    "             train_conditions={},\n",
    "             val_conditions={})\n",
    "D = Variable(name='D',\n",
    "             order=0,\n",
    "             domain=Interval(low_bound=D_low,\n",
    "                             up_bound=D_up),\n",
    "             train_conditions={},\n",
    "             val_conditions={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the wanted boundary conditions to x and t and define the norm that will be used in all training conditions. Every condition has a name string, a torch Module as a given norm (L2 in this case), a weight used during optimization, and the option to plot the training data points to tensorboard during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = torch.nn.MSELoss()\n",
    "\n",
    "# Dirichlet functions should act on the given dictionarys of numpy arrays:\n",
    "def x_dirichlet_fun(x):\n",
    "    return 0\n",
    "# a DirichtletCondition generates data points at which the dirichlet_fun is evaluated\n",
    "# and the Dirichlet condition is enforced. There are different strategys for sampling,\n",
    "# 'random' and 'grid' are always implemented.\n",
    "\n",
    "# The flag 'whole_batch=False' can be used to pass a point-wise defined dirichlet_fun.\n",
    "# This avoids the batch-wise notion, which can make function definitions complicated\n",
    "x.add_train_condition(DirichletCondition(dirichlet_fun=x_dirichlet_fun,\n",
    "                                         solution_name=u,\n",
    "                                         whole_batch=False,\n",
    "                                         name='dirichlet',\n",
    "                                         sampling_strategy='random',\n",
    "                                         boundary_sampling_strategy='random',\n",
    "                                         norm=norm,\n",
    "                                         weight=1.0,\n",
    "                                         dataset_size=2000,\n",
    "                                         data_plot_variables=('x','t')))\n",
    "\n",
    "# the same can be done to achieve an initial condition for the time axis:\n",
    "def t_dirichlet_fun(x):\n",
    "    return temp_hot*np.sin(np.pi/w*x[0])*np.sin(np.pi/h*x[1])\n",
    "# to get only initial (and not end-) values, we can set boundary_sampling_strategy to sample\n",
    "# only one bound of the interval\n",
    "t.add_train_condition(DirichletCondition(dirichlet_fun=t_dirichlet_fun,\n",
    "                                         solution_name=u,\n",
    "                                         name='dirichlet',\n",
    "                                         whole_batch=False,\n",
    "                                         norm=norm,\n",
    "                                         dataset_size=2000,\n",
    "                                         boundary_sampling_strategy='lower_bound_only',\n",
    "                                         data_plot_variables=('x','t')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same notation, we can also define a PDE-condition to the inner of the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pde function handle takes the output and the input (as a dict again) of the network. We can use\n",
    "# functions like 'laplacian' from the utils part to compute common differential operators.\n",
    "\n",
    "# similar to the boundary conditions, the names of the local variables should match the global\n",
    "# variables or parameters.\n",
    "# But while 'data_fun's use np arrays and can be implemented pointwise, functions that are called\n",
    "# in every iteration of the training (like PDEs) work exclusively with batches of torch data\n",
    "def pde(u, x, t, D):\n",
    "    return grad(u, t) - D*laplacian(u, x)\n",
    "\n",
    "# a DiffEqCondition works similar to the boundary condiitions\n",
    "train_cond = DiffEqCondition(pde=pde,\n",
    "                             name='pde',\n",
    "                             norm=norm,\n",
    "                             sampling_strategy='random',\n",
    "                             weight=1.0,\n",
    "                             dataset_size=16000,\n",
    "                             data_plot_variables=('x','t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison during validation, we solve the problem for some D using a simple FDM scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "domain_dic = {'x': [[0, w], [0, h]]}\n",
    "dx, dy = 0.5, 0.5\n",
    "step_width_dict = {'x': [dx, dy]}\n",
    "time_interval = [t0, tend]\n",
    "\n",
    "D_list = [5, 10, 15, 20, 25]\n",
    "# ^Here you can add many different values for D, e.g [18.8,2.5,20,....]\n",
    "# The FDM-Methode will compute solutions for all D.\n",
    "# For too many D this will become really memory expensive, since\n",
    "# the FDM uses a forward euler!\n",
    "fdm_start = timer()\n",
    "domain, time, u_ = FDM(domain_dic, step_width_dict, time_interval,\n",
    "                      D_list, t_dirichlet_fun)\n",
    "fdm_end = timer()\n",
    "print('Time for FDM-Solution:', fdm_end-fdm_start)\n",
    "data_x, data_u = create_validation_data(domain, time, u_, D_list, D_is_input=True)\n",
    "# True: if D is input of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the FDM solution, we can also define a DataCondition that measures the distance between the computed solution and the FDM solution (w.r.t. max-norm) during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfNorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_a, input_b):\n",
    "        return torch.max(torch.abs(input_a-input_b))\n",
    "\n",
    "max_norm = InfNorm()\n",
    "\n",
    "val_cond = DataCondition(solution_name=u,\n",
    "                         data_inp=data_x,\n",
    "                         data_out=data_u,\n",
    "                         name='validation',\n",
    "                         norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables (with their boundary conditions) as well as the conditions for the inner part of the domain are collected in a Setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setup = Setting(variables=(x, t, D),\n",
    "                train_conditions={'pde': train_cond},\n",
    "                val_conditions={'validation': val_cond},\n",
    "                solution_dims={u: 1},\n",
    "                n_iterations=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem defined by setting using a PINN, we define a solver. A plotter can help us to visualize intermediate results in the tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = Plotter(solution_name=u,\n",
    "                  plot_variables=setup.variables['x'],\n",
    "                  points=400,\n",
    "                  dic_for_other_variables={'t': 1.0, 'D': 10.0},\n",
    "                  all_variables=setup.variables,\n",
    "                  log_interval=1)\n",
    "\n",
    "# the solver takes a neural network model and the created setting\n",
    "# and defines which optimizer is used in training\n",
    "\n",
    "solver = PINNModule(model=SimpleFCN(variable_dims=setup.variable_dims,\n",
    "                                    solution_dims=setup.solution_dims,\n",
    "                                    depth=5,\n",
    "                                    width=30),\n",
    "                    optimizer=torch.optim.Adam, \n",
    "                    lr=1e-2,\n",
    "                    #log_plotter=plotter\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a lightning trainer and train the model. A lightning trainer has many options, some of them are used here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus='-1' if torch.cuda.is_available() else None,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     benchmark=True,\n",
    "                     check_val_every_n_epoch=2,\n",
    "                     log_every_n_steps=15,\n",
    "                     max_epochs=3,\n",
    "                     logger=False,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "trainer.fit(solver, setup)\n",
    "\n",
    "setup = Setting(variables=(x, t, D),\n",
    "                train_conditions={'pde': train_cond},\n",
    "                val_conditions={'validation': val_cond},\n",
    "                solution_dims={u: 1},\n",
    "                n_iterations=500)\n",
    "solver.optimizer = torch.optim.LBFGS\n",
    "solver.lr = 1e-1\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(gpus='-1' if torch.cuda.is_available() else None,\n",
    "                     logger=False,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     benchmark=True,\n",
    "                     check_val_every_n_epoch=50,\n",
    "                     log_every_n_steps=1,\n",
    "                     max_epochs=2,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "trainer.fit(solver, setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also measure the time needed to evaluate the model (on gpu or cpu) and plot the obtained approximation of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchphysics.problem.datacreator import InnerDataCreator\n",
    "import time\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "dc = InnerDataCreator(variables={'x': x, 't': t, 'D': D},\n",
    "                      dataset_size=[2000, 400, 1], \n",
    "                      # Here we use different number of points for each variable\n",
    "                      # x has 100 points, t = 20 and D only 1 (constant) value.\n",
    "                      # The number of total points are all different combinations:\n",
    "                      # -> 2000 different points\n",
    "                      sampling_strategy='grid')\n",
    "input_dic = dc.get_data() # create the data\n",
    "# Change the D (if you want):\n",
    "input_dic['D'] = 10 * np.ones((len(input_dic['D']), 1))\n",
    "# cast everything to tensors:\n",
    "for name in input_dic:\n",
    "    input_dic[name] = torch.FloatTensor(input_dic[name]).to(device)\n",
    "# Evaluate\n",
    "solver = solver.to(device)\n",
    "start = time.time()\n",
    "pred = solver.forward(input_dic) \n",
    "end = time.time()\n",
    "print('Time to evaluate model:', end - start)\n",
    "print('For:', len(input_dic['x']), 'different points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchphysics.utils.plot import _plot\n",
    "solver = solver.to('cpu')\n",
    "D = 11\n",
    "fig = _plot(model=solver.model, solution_name=u, plot_variables=x, points=200, angle=[30, 30], \n",
    "            dic_for_other_variables={'t' : 0, 'D' : D})\n",
    "min_inside, max_inside = get_min_max_inside(solver.model, solution_name=u, domain_variable=x, \n",
    "                                            resolution=1600, \n",
    "                                            dic_for_other_variables={'t': 3, 'D': D})\n",
    "min_bound, max_bound = get_min_max_boundary(solver.model, solution_name=u, boundary_variable=x, \n",
    "                                            resolution=1000, \n",
    "                                            dic_for_other_variables={'t': 3, 'D': D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5471d372aecbf763f050aece93ed861d8318175083d9494b12a3b32f7831ffe8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

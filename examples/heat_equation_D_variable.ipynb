{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39464bitboschpdeconda6beed50046b64076abad6692f0060fc7",
   "display_name": "Python 3.9.4 64-bit ('bosch-pde': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Solve a heat equation for variable diffusion D\n",
    "This script includes D as an input to the network, such that the trained network solves the heat equation for a whole range of diffusion coefficients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from neural_diff_eq.problem import (Variable,\n",
    "                                    Setting)\n",
    "from neural_diff_eq.problem.domain import (Rectangle,\n",
    "                                           Interval)\n",
    "from neural_diff_eq.problem.condition import (DirichletCondition,\n",
    "                                              DiffEqCondition,\n",
    "                                              DataCondition)\n",
    "from neural_diff_eq.models.fcn import SimpleFCN\n",
    "from neural_diff_eq import PINNModule\n",
    "from neural_diff_eq.utils import laplacian, gradient\n",
    "from neural_diff_eq.utils.fdm import FDM, create_validation_data\n",
    "from neural_diff_eq.utils.plot import Plotter\n",
    "\n",
    "from neural_diff_eq.datamodule import ProblemDataModule\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # select GPUs to use\n",
    "\n",
    "#pl.seed_everything(43) # set a global seed"
   ]
  },
  {
   "source": [
    "We define some parameters that describe the setting:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 50, 50\n",
    "t0, tend = 0, 1\n",
    "temp_hot = 10\n",
    "D_low, D_up = 5, 25  # set here the interval boundary for D"
   ]
  },
  {
   "source": [
    "We define the independent variables of the PDE, which will later determine the inputs to the NN. Every variable has a domain and can have one or more boundary conditions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(name='x',\n",
    "             order=2,\n",
    "             domain=Rectangle(corner_dl=[0, 0],\n",
    "                              corner_dr=[w, 0],\n",
    "                              corner_tl=[0, h]),\n",
    "             train_conditions={},\n",
    "             val_conditions={})\n",
    "t = Variable(name='t',\n",
    "             order=1,\n",
    "             domain=Interval(low_bound=0,\n",
    "                             up_bound=tend),\n",
    "             train_conditions={},\n",
    "             val_conditions={})\n",
    "D = Variable(name='D',\n",
    "             order=0,\n",
    "             domain=Interval(low_bound=D_low,\n",
    "                             up_bound=D_up),\n",
    "             train_conditions={},\n",
    "             val_conditions={})"
   ]
  },
  {
   "source": [
    "Now we add the wanted boundary conditions to x and t and define the norm that will be used in all training conditions. Every condition has a name string, a torch Module as a given norm (L2 in this case), a weight used during optimization, and the option to plot the training data points to tensorboard during training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = torch.nn.MSELoss()\n",
    "\n",
    "# Dirichlet functions should act on the given dictionarys of numpy arrays:\n",
    "def x_dirichlet_fun(input):\n",
    "    return np.zeros_like(input['t'])\n",
    "# a DirichtletCondition generates data points at which the dirichlet_fun is evaluated\n",
    "# and the Dirichlet condition is enforced. There are different strategys for sampling,\n",
    "# 'random' and 'grid' are always implemented. However, the current state of 'grid' still has\n",
    "# some problems in the combination of variables and is therefore not recommended yet.\n",
    "x.add_train_condition(DirichletCondition(dirichlet_fun=x_dirichlet_fun,\n",
    "                                         name='dirichlet',\n",
    "                                         sampling_strategy='random',\n",
    "                                         boundary_sampling_strategy='random',\n",
    "                                         norm=norm,\n",
    "                                         weight=1.0,\n",
    "                                         dataset_size=500,\n",
    "                                         data_plot_variables=('x','t')))\n",
    "\n",
    "# the same can be done to achieve an initial condition for the time axis:\n",
    "def t_dirichlet_fun(input):\n",
    "    return temp_hot*np.sin(np.pi/w*input['x'][:, :1])*np.sin(np.pi/h*input['x'][:, 1:])\n",
    "# to get only initial (and not end-) values, we can set boundary_sampling_strategy to sample\n",
    "# only one bound of the interval\n",
    "t.add_train_condition(DirichletCondition(dirichlet_fun=t_dirichlet_fun,\n",
    "                                         name='dirichlet',\n",
    "                                         norm=norm,\n",
    "                                         dataset_size=500,\n",
    "                                         boundary_sampling_strategy='lower_bound_only',\n",
    "                                         data_plot_variables=('x','t')))\n"
   ]
  },
  {
   "source": [
    "Using the same notation, we can also define a PDE-condition to the inner of the domain."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pde function handle takes the output and the input (as a dict again) of the network. We can use\n",
    "# functions like 'laplacian' from the utils part to compute common differential operators.\n",
    "def pde(u, input):\n",
    "    return gradient(u, input['t']) - input['D']*laplacian(u, input['x'])\n",
    "\n",
    "# a DiffEqCondition works similar to the boundary condiitions\n",
    "train_cond = DiffEqCondition(pde=pde,\n",
    "                             name='pde',\n",
    "                             norm=norm,\n",
    "                             sampling_strategy='random',\n",
    "                             weight=1.0,\n",
    "                             dataset_size=5000,\n",
    "                             data_plot_variables=('x','t'))"
   ]
  },
  {
   "source": [
    "For comparison during validation, we solve the problem for some D using a simple FDM scheme:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time for FDM-Solution: 0.4438511421903968\n"
     ]
    }
   ],
   "source": [
    "domain_dic = {'x': [[0, w], [0, h]]}\n",
    "dx, dy = 0.5, 0.5\n",
    "step_width_dict = {'x': [dx, dy]}\n",
    "time_interval = [t0, tend]\n",
    "\n",
    "D_list = [5, 10, 15, 20, 25]\n",
    "# ^Here you can add many different values for D, e.g [18.8,2.5,20,....]\n",
    "# The FDM-Methode will compute solutions for all D.\n",
    "# For too many D this will become really memory expensive, since\n",
    "# the FDM uses a forward euler!\n",
    "fdm_start = timer()\n",
    "domain, time, u = FDM(domain_dic, step_width_dict, time_interval,\n",
    "                      D_list, t_dirichlet_fun)\n",
    "fdm_end = timer()\n",
    "print('Time for FDM-Solution:', fdm_end-fdm_start)\n",
    "data_x, data_u = create_validation_data(domain, time, u, D_list, D_is_input=True)\n",
    "# True: if D is input of the model"
   ]
  },
  {
   "source": [
    "Using the FDM solution, we can also define a DataCondition that measures the distance between the computed solution and the FDM solution (w.r.t. max-norm) during validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfNorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_a, input_b):\n",
    "        return torch.max(torch.abs(input_a-input_b))\n",
    "\n",
    "max_norm = InfNorm()\n",
    "\n",
    "val_cond = DataCondition(data_x=data_x,\n",
    "                         data_u=data_u,\n",
    "                         name='validation',\n",
    "                         norm=norm)"
   ]
  },
  {
   "source": [
    "The variables (with their boundary conditions) as well as the conditions for the inner part of the domain are collected in a Setting:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = Setting(variables=(x, t, D),\n",
    "                train_conditions={'pde': train_cond},\n",
    "                val_conditions={'validation': val_cond})"
   ]
  },
  {
   "source": [
    "To solve the problem defined by setting using a PINN, we define a solver. A plotter can help us to visualize intermediate results in the tensorboard."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = Plotter(plot_variables=setup.variables['x'],\n",
    "                  points=400,\n",
    "                  dic_for_other_variables={'t': 1.0, 'D': 15.0},\n",
    "                  all_variables=setup.variables,\n",
    "                  log_interval=1)\n",
    "\n",
    "# the solver takes a neural network model and the created setting\n",
    "# and defines which optimizer is used in training\n",
    "solver = PINNModule(model=SimpleFCN(input_dim=4,\n",
    "                                    depth=4,\n",
    "                                    width=20),\n",
    "                    problem=setup,\n",
    "                    optimizer=torch.optim.Adam,\n",
    "                    lr=1e-3,\n",
    "                    #log_plotter=plotter\n",
    "                    )\n",
    "datamod = ProblemDataModule(problem=setup,n_iterations=100)"
   ]
  },
  {
   "source": [
    "Finally, we define a lightning trainer and train the model. A lightning trainer has many options, some of them are used here:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | SimpleFCN | 1.8 K \n",
      "------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n",
      "Epoch 9:  99%|█████████▉| 100/101 [00:04<00:00, 21.89it/s, loss=0.323, v_num=128]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 101/101 [00:05<00:00, 17.05it/s, loss=0.323, v_num=128]\n",
      "Epoch 19:  99%|█████████▉| 100/101 [00:04<00:00, 23.43it/s, loss=0.0767, v_num=128]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 101/101 [00:05<00:00, 18.07it/s, loss=0.0767, v_num=128]\n",
      "Epoch 19: 100%|██████████| 101/101 [00:05<00:00, 18.06it/s, loss=0.0767, v_num=128]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=None,#'-1',\n",
    "                     num_sanity_val_steps=1,\n",
    "                     check_val_every_n_epoch=10,\n",
    "                     log_every_n_steps=1,\n",
    "                     max_epochs=20,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "trainer.fit(solver, datamod)"
   ]
  }
 ]
}